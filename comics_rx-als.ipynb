{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comics Rx\n",
    "## [A comic book recommendation system](https://github.com/MangrobanGit/comics_rx)\n",
    "<img src=\"https://images.unsplash.com/photo-1514329926535-7f6dbfbfb114?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=2850&q=80\" width=\"400\" align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. ALS with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2  # 1 would be where you need to specify the files\n",
    "#%aimport data_fcns\n",
    "\n",
    "import pandas as pd # dataframes\n",
    "import os\n",
    "import gspread_pandas\n",
    "from gspread_pandas import Spread, Client # gsheets interaction\n",
    "\n",
    "# Data storage\n",
    "from sqlalchemy import create_engine # SQL helper\n",
    "import psycopg2 as psql #PostgreSQL DBs\n",
    "\n",
    "# import necessary libraries\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.sql.types import (StructType, StructField, IntegerType\n",
    "                               ,FloatType, LongType )\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Custom\n",
    "import data_fcns as dfc\n",
    "import keys  # Custom keys lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate SparkSession object\n",
    "spark = pyspark.sql.SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "# spark = SparkSession.builder.master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "                    StructField('userID', IntegerType())\n",
    "                    ,StructField('movieID', IntegerType())\n",
    "                    ,StructField('rating', FloatType())\n",
    "                    ,StructField('timestamp', LongType())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data\n",
    "\n",
    "There is way to directly hit PostgreSQL through JDBC, but I don't know how to do that yet. So have worked around by saving the candidate dataset to JSON, and then will use that as input to Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "comics = spark.read.json('raw_data/trans.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_num: string, comic_title: string, date_sold: bigint, item_id: string, publisher: string, qty_sold: bigint, title_and_num: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persist the data\n",
    "comics.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### read in the dataset into pyspark DataFrame\n",
    "testing = spark.read.csv('./data/ratings.csv'\n",
    "                               , inferSchema=False\n",
    "                               , schema=schema\n",
    "                               , header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account_num: string (nullable = true)\n",
      " |-- comic_title: string (nullable = true)\n",
      " |-- date_sold: long (nullable = true)\n",
      " |-- item_id: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- qty_sold: long (nullable = true)\n",
      " |-- title_and_num: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check schema\n",
    "comics.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More exploration/testing\n",
    "\n",
    "We won't be using pandas dataframes in the matrix factorization through Spark, but let's cast to one anyway as it will be easier to work with for EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 494703 entries, 0 to 494702\n",
      "Data columns (total 7 columns):\n",
      "account_num      494703 non-null object\n",
      "comic_title      494703 non-null object\n",
      "date_sold        494703 non-null int64\n",
      "item_id          494703 non-null object\n",
      "publisher        494703 non-null object\n",
      "qty_sold         494703 non-null int64\n",
      "title_and_num    494703 non-null object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 26.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# cast to Pandas dataframe to turn timestamp data to datetime and check nulls. \n",
    "comics_df = comics.select('*').toPandas()\n",
    "comics_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_num</th>\n",
       "      <th>comic_title</th>\n",
       "      <th>date_sold</th>\n",
       "      <th>item_id</th>\n",
       "      <th>publisher</th>\n",
       "      <th>qty_sold</th>\n",
       "      <th>title_and_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00174</td>\n",
       "      <td>Filler Bunny (SLG)</td>\n",
       "      <td>1313344863000</td>\n",
       "      <td>DCD151935</td>\n",
       "      <td>Amaze Ink Slave Labor Graphics</td>\n",
       "      <td>1</td>\n",
       "      <td>Filler Bunny #2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00593</td>\n",
       "      <td>Gargoyles (SLG)</td>\n",
       "      <td>1340374297000</td>\n",
       "      <td>DCD341726</td>\n",
       "      <td>Amaze Ink Slave Labor Graphics</td>\n",
       "      <td>1</td>\n",
       "      <td>Gargoyles #6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00226</td>\n",
       "      <td>Royal Historian of Oz (SLG)</td>\n",
       "      <td>1279720987000</td>\n",
       "      <td>DCD416182</td>\n",
       "      <td>Amaze Ink Slave Labor Graphics</td>\n",
       "      <td>1</td>\n",
       "      <td>Royal Historian of Oz #1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00399</td>\n",
       "      <td>Royal Historian of Oz (SLG)</td>\n",
       "      <td>1279136980000</td>\n",
       "      <td>DCD416182</td>\n",
       "      <td>Amaze Ink Slave Labor Graphics</td>\n",
       "      <td>1</td>\n",
       "      <td>Royal Historian of Oz #1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00237</td>\n",
       "      <td>Royal Historian of Oz (SLG)</td>\n",
       "      <td>1279535944000</td>\n",
       "      <td>DCD416182</td>\n",
       "      <td>Amaze Ink Slave Labor Graphics</td>\n",
       "      <td>1</td>\n",
       "      <td>Royal Historian of Oz #1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  account_num                  comic_title      date_sold    item_id  \\\n",
       "0       00174           Filler Bunny (SLG)  1313344863000  DCD151935   \n",
       "1       00593              Gargoyles (SLG)  1340374297000  DCD341726   \n",
       "2       00226  Royal Historian of Oz (SLG)  1279720987000  DCD416182   \n",
       "3       00399  Royal Historian of Oz (SLG)  1279136980000  DCD416182   \n",
       "4       00237  Royal Historian of Oz (SLG)  1279535944000  DCD416182   \n",
       "\n",
       "                        publisher  qty_sold             title_and_num  \n",
       "0  Amaze Ink Slave Labor Graphics         1           Filler Bunny #2  \n",
       "1  Amaze Ink Slave Labor Graphics         1              Gargoyles #6  \n",
       "2  Amaze Ink Slave Labor Graphics         1  Royal Historian of Oz #1  \n",
       "3  Amaze Ink Slave Labor Graphics         1  Royal Historian of Oz #1  \n",
       "4  Amaze Ink Slave Labor Graphics         1  Royal Historian of Oz #1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's double check the data is how we expect it\n",
    "comics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "comics_df['dt'] = pd.to_datetime(comics_df['date_sold'], unit='ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. Reverse-confirmed versus the original transactions dataframe in the other notebook that this datetime is correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep for ALS\n",
    "\n",
    "Let's aggregate the data to the two columns we need:\n",
    "- `account_num` - This is the identifier for individual customers.\n",
    "\n",
    "\n",
    "- `comic_title` - The comic. Represents individual volumes/runs of a comic.\n",
    "\n",
    "\n",
    "- `score` - We need to figure out what we want to use to act as a `score`. If these were Amazon items then review scores would be natural fit; but we don't have that. We can maybe use a binary flag of `bought`/`not bought`. Or we can use the `qty_sold`. This might be interesting in that it might capture some interesting behavior from comic 'collectors/speculators'. Since this is first pass, I'm curious as to what `qty_sold` might do!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only care about `account_num`, `comic_title` and `qty_sold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_num: string, comic_title: string, qty_sold: bigint]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comics_sold = comics[['account_num', 'comic_title', 'qty_sold']]\n",
    "comics_sold.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_num: string, comic_title: string, sum(qty_sold): bigint]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_comics_sold = comics_sold.groupBy(['account_num', 'comic_title']).agg({'qty_sold':'sum'})\n",
    "total_comics_sold.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's take a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------+\n",
      "|account_num|         comic_title|sum(qty_sold)|\n",
      "+-----------+--------------------+-------------+\n",
      "|      01858|Afterlife With Ar...|            5|\n",
      "|      02247|Bubblegun VOL 2 (...|            1|\n",
      "|      00191|    Caliban (Avatar)|            7|\n",
      "|      00487|Captain Swing (Av...|            2|\n",
      "|      00029|God Is Dead (Avatar)|            7|\n",
      "|      01260| Providence (Avatar)|            1|\n",
      "|      00172|   Supergod (Avatar)|            3|\n",
      "|      01132|Futurama Annual (...|            3|\n",
      "|      02493|       Abbott (Boom)|            3|\n",
      "|      00298|Adventure Time (B...|            2|\n",
      "+-----------+--------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_comics_sold.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't like that default column name. Let's fix that to be `qty_sold` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_num: string, comic_title: string, qty_sold: bigint]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_comics_sold = total_comics_sold.select(\n",
    "    *[col(s).alias('qty_sold') if s == 'sum(qty_sold)' \n",
    "      else s \n",
    "      for s in total_comics_sold.columns])\n",
    "total_comics_sold.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------+\n",
      "|account_num|         comic_title|qty_sold|\n",
      "+-----------+--------------------+--------+\n",
      "|      01858|Afterlife With Ar...|       5|\n",
      "|      02247|Bubblegun VOL 2 (...|       1|\n",
      "|      00191|    Caliban (Avatar)|       7|\n",
      "|      00487|Captain Swing (Av...|       2|\n",
      "|      00029|God Is Dead (Avatar)|       7|\n",
      "|      01260| Providence (Avatar)|       1|\n",
      "|      00172|   Supergod (Avatar)|       3|\n",
      "|      01132|Futurama Annual (...|       3|\n",
      "|      02493|       Abbott (Boom)|       3|\n",
      "|      00298|Adventure Time (B...|       2|\n",
      "+-----------+--------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_comics_sold.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatting\n",
    "\n",
    "Sooooooo, I forgot that the values need to be numeric. So need to fix that.\n",
    "\n",
    "First, let's convert `account_num` to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_int_udf = F.udf(dfc.make_int, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_num_col = total_comics_sold['account_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = total_comics_sold.withColumn('account_id'\n",
    "                                        ,to_int_udf(account_num_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------+----------+\n",
      "|account_num|         comic_title|qty_sold|account_id|\n",
      "+-----------+--------------------+--------+----------+\n",
      "|      01858|Afterlife With Ar...|       5|      1858|\n",
      "|      02247|Bubblegun VOL 2 (...|       1|      2247|\n",
      "|      00191|    Caliban (Avatar)|       7|       191|\n",
      "|      00487|Captain Swing (Av...|       2|       487|\n",
      "|      00029|God Is Dead (Avatar)|       7|        29|\n",
      "|      01260| Providence (Avatar)|       1|      1260|\n",
      "|      00172|   Supergod (Avatar)|       3|       172|\n",
      "|      01132|Futurama Annual (...|       3|      1132|\n",
      "|      02493|       Abbott (Boom)|       3|      2493|\n",
      "|      00298|Adventure Time (B...|       2|       298|\n",
      "+-----------+--------------------+--------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to find a way to give ids to the `comic_title`. Kind of clunky, but I do have the version in PostgreSQL of the big table. I can just build an ID table up there as source of truth. I could do something on PySpark side, but then think would want to save it somewhere (e.g. the DB) anyway. So might as well do it from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS Model\n",
    "\n",
    "Let's start with  train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test set\n",
    "(train, test) = total_comics_sold.randomSplit([.8, .2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ALS instance and fit model\n",
    "als = ALS(maxIter=10,\n",
    "          rank=10,\n",
    "          userCol='account_num',\n",
    "          itemCol='comic_title',\n",
    "          ratingCol='qty_sold',\n",
    "          seed=41916)\n",
    "\n",
    "model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Cleaning Tasks I will ignore as I race to get my FSM</font>\n",
    "- Remove outlier users (eBay, one-timers, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
