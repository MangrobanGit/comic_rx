{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comics Rx\n",
    "## [A comic book recommendation system](https://github.com/MangrobanGit/comics_rx)\n",
    "<img src=\"https://images.unsplash.com/photo-1514329926535-7f6dbfbfb114?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=2850&q=80\" width=\"400\" align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2  # 1 would be where you need to specify the files\n",
    "#%aimport data_fcns\n",
    "\n",
    "import pandas as pd # dataframes\n",
    "import os\n",
    "import gspread_pandas\n",
    "from gspread_pandas import Spread, Client # gsheets interaction\n",
    "\n",
    "# Data storage\n",
    "from sqlalchemy import create_engine # SQL helper\n",
    "import psycopg2 as psql #PostgreSQL DBs\n",
    "\n",
    "# import necessary libraries\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# from pyspark.sql.types import (StructType, StructField, IntegerType\n",
    "#                                ,FloatType, LongType, StringType)\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, explode, lit, isnan, when, count\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Custom\n",
    "import data_fcns as dfc\n",
    "import keys  # Custom keys lib\n",
    "import comic_recs as cr\n",
    "\n",
    "# Data storage\n",
    "from sqlalchemy import create_engine # SQL helper\n",
    "import psycopg2 as psql #PostgreSQL DBs\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate SparkSession object\n",
    "spark = pyspark.sql.SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "# spark = SparkSession.builder.master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jdbcDF = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql:dbserver\") \\\n",
    "    .option(\"dbtable\", \"schema.tablename\") \\\n",
    "    .option(\"user\", \"username\") \\\n",
    "    .option(\"password\", \"password\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define path to secret\n",
    "secret_path_aws = os.path.join(os.environ['HOME'], '.secret', \n",
    "                           'aws_ps_flatiron.json')\n",
    "secret_path_aws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aws_keys = keys.get_keys(secret_path_aws)\n",
    "user = aws_keys['user']\n",
    "ps = aws_keys['password']\n",
    "host = aws_keys['host']\n",
    "db = aws_keys['db_name']\n",
    "\n",
    "aws_ps_engine = ('postgresql://' + user + ':' + ps + '@' + host + '/' + db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup PSQL connection\n",
    "conn = psql.connect(\n",
    "    database=db,\n",
    "    user=user,\n",
    "    password=ps,\n",
    "    host=host,\n",
    "    port='5432'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data\n",
    "\n",
    "There is way to directly hit PostgreSQL through JDBC, but I don't know how to do that yet. So have worked around by saving the candidate dataset to JSON, and then will use that as input to Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = spark.read.json('raw_data/trans_filtered.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_num: string, comic_title: string, date_sold: bigint, item_id: string, publisher: string, qty_sold: bigint, title_and_num: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persist the data\n",
    "trans.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327839 7\n"
     ]
    }
   ],
   "source": [
    "print(trans.count(), len(trans.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account_num: string (nullable = true)\n",
      " |-- comic_title: string (nullable = true)\n",
      " |-- date_sold: long (nullable = true)\n",
      " |-- item_id: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- qty_sold: long (nullable = true)\n",
      " |-- title_and_num: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check schema\n",
    "trans.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More exploration/testing\n",
    "\n",
    "We won't be using pandas dataframes in the matrix factorization through Spark, but let's cast to one anyway as it will be easier to work with for EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 327839 entries, 0 to 327838\n",
      "Data columns (total 7 columns):\n",
      "account_num      327839 non-null object\n",
      "comic_title      327839 non-null object\n",
      "date_sold        327839 non-null int64\n",
      "item_id          327839 non-null object\n",
      "publisher        327839 non-null object\n",
      "qty_sold         327839 non-null int64\n",
      "title_and_num    327839 non-null object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 17.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# cast to Pandas dataframe to turn timestamp data to datetime and check nulls. \n",
    "trans_df = trans.select('*').toPandas()\n",
    "trans_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_num</th>\n",
       "      <th>comic_title</th>\n",
       "      <th>date_sold</th>\n",
       "      <th>item_id</th>\n",
       "      <th>publisher</th>\n",
       "      <th>qty_sold</th>\n",
       "      <th>title_and_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00399</td>\n",
       "      <td>Royal Historian of Oz (SLG)</td>\n",
       "      <td>1279136980000</td>\n",
       "      <td>DCD416182</td>\n",
       "      <td>Amaze Ink Slave Labor Graphics</td>\n",
       "      <td>1</td>\n",
       "      <td>Royal Historian of Oz #1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00327</td>\n",
       "      <td>Royal Historian of Oz (SLG)</td>\n",
       "      <td>1288543119000</td>\n",
       "      <td>DCD416182</td>\n",
       "      <td>Amaze Ink Slave Labor Graphics</td>\n",
       "      <td>1</td>\n",
       "      <td>Royal Historian of Oz #1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00327</td>\n",
       "      <td>Royal Historian of Oz (SLG)</td>\n",
       "      <td>1288543119000</td>\n",
       "      <td>DCD423794</td>\n",
       "      <td>Amaze Ink Slave Labor Graphics</td>\n",
       "      <td>1</td>\n",
       "      <td>Royal Historian of Oz #2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01065</td>\n",
       "      <td>Warlord of Io &amp; Other Storie (SLG)</td>\n",
       "      <td>1412166247000</td>\n",
       "      <td>DCD390709</td>\n",
       "      <td>Amaze Ink Slave Labor Graphics</td>\n",
       "      <td>1</td>\n",
       "      <td>Warlord of Io &amp; Other Stories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01033</td>\n",
       "      <td>Afterlife With Archie (Archie)</td>\n",
       "      <td>1390505789000</td>\n",
       "      <td>DCD630105</td>\n",
       "      <td>Archie Comics</td>\n",
       "      <td>1</td>\n",
       "      <td>Afterlife With Archie #1 2nd P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  account_num                         comic_title      date_sold    item_id  \\\n",
       "0       00399         Royal Historian of Oz (SLG)  1279136980000  DCD416182   \n",
       "1       00327         Royal Historian of Oz (SLG)  1288543119000  DCD416182   \n",
       "2       00327         Royal Historian of Oz (SLG)  1288543119000  DCD423794   \n",
       "3       01065  Warlord of Io & Other Storie (SLG)  1412166247000  DCD390709   \n",
       "4       01033      Afterlife With Archie (Archie)  1390505789000  DCD630105   \n",
       "\n",
       "                        publisher  qty_sold                   title_and_num  \n",
       "0  Amaze Ink Slave Labor Graphics         1        Royal Historian of Oz #1  \n",
       "1  Amaze Ink Slave Labor Graphics         1        Royal Historian of Oz #1  \n",
       "2  Amaze Ink Slave Labor Graphics         1        Royal Historian of Oz #2  \n",
       "3  Amaze Ink Slave Labor Graphics         1   Warlord of Io & Other Stories  \n",
       "4                   Archie Comics         1  Afterlife With Archie #1 2nd P  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's double check the data is how we expect it\n",
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df['dt'] = pd.to_datetime(trans_df['date_sold'], unit='ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. Reverse-confirmed versus the original transactions dataframe in the other notebook that this datetime is correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep for ALS\n",
    "\n",
    "Let's aggregate the data to the two columns we need:\n",
    "- `account_num` - This is the identifier for individual customers.\n",
    "\n",
    "\n",
    "- `comic_title` - The comic. Represents individual volumes/runs of a comic.\n",
    "\n",
    "\n",
    "- `score` - We need to figure out what we want to use to act as a `score`. If these were Amazon items then review scores would be natural fit; but we don't have that. We can maybe use a binary flag of `bought`/`not bought`. Or we can use the `qty_sold`. This might be interesting in that it might capture some interesting behavior from comic 'collectors/speculators'. Since this is first pass, I'm curious as to what `qty_sold` might do!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only care about `account_num`, `comic_title` and `qty_sold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_num: string, comic_title: string, qty_sold: bigint]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comics_sold = trans[['account_num', 'comic_title', 'qty_sold']]\n",
    "comics_sold.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "comics_sold = comics_sold.withColumn('bought', lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------+------+\n",
      "|account_num|         comic_title|qty_sold|bought|\n",
      "+-----------+--------------------+--------+------+\n",
      "|      00399|Royal Historian o...|       1|     1|\n",
      "|      00327|Royal Historian o...|       1|     1|\n",
      "|      00327|Royal Historian o...|       1|     1|\n",
      "|      01065|Warlord of Io & O...|       1|     1|\n",
      "|      01033|Afterlife With Ar...|       1|     1|\n",
      "|      01333|Afterlife With Ar...|       1|     1|\n",
      "|      00946|Afterlife With Ar...|       1|     1|\n",
      "|      01278|Afterlife With Ar...|       1|     1|\n",
      "|      01212|Afterlife With Ar...|       1|     1|\n",
      "|      00877|Afterlife With Ar...|       1|     1|\n",
      "+-----------+--------------------+--------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comics_sold.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_num: string, comic_title: string, qty_sold: bigint]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comics_sold = trans[['account_num', 'comic_title', 'qty_sold']]\n",
    "comics_sold.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_num: string, comic_title: string, sum(qty_sold): bigint]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_comics_sold = comics_sold.groupBy(['account_num', 'comic_title']).agg({'qty_sold':'sum'})\n",
    "total_comics_sold.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's take a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------+\n",
      "|account_num|         comic_title|sum(qty_sold)|\n",
      "+-----------+--------------------+-------------+\n",
      "|      02247|Bubblegun VOL 2 (...|            1|\n",
      "|      00487|Captain Swing (Av...|            2|\n",
      "|      00029|God Is Dead (Avatar)|            7|\n",
      "|      01260| Providence (Avatar)|            1|\n",
      "|      00172|   Supergod (Avatar)|            3|\n",
      "|      02493|       Abbott (Boom)|            3|\n",
      "|      00052|Adventure Time Ma...|            6|\n",
      "|      00032|Big Trouble In Li...|           11|\n",
      "|      01149| Broken World (Boom)|            2|\n",
      "|      01489|Jim Henson Labyri...|            1|\n",
      "+-----------+--------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_comics_sold.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61871 3\n"
     ]
    }
   ],
   "source": [
    "print(total_comics_sold.count(), len(total_comics_sold.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_comics_sold = total_comics_sold.withColumn('bought', lit(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't like that default column name. Let's fix that to be `qty_sold` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------+------+\n",
      "|account_num|         comic_title|sum(qty_sold)|bought|\n",
      "+-----------+--------------------+-------------+------+\n",
      "|      02247|Bubblegun VOL 2 (...|            1|     1|\n",
      "|      00487|Captain Swing (Av...|            2|     1|\n",
      "|      00029|God Is Dead (Avatar)|            7|     1|\n",
      "|      01260| Providence (Avatar)|            1|     1|\n",
      "|      00172|   Supergod (Avatar)|            3|     1|\n",
      "|      02493|       Abbott (Boom)|            3|     1|\n",
      "|      00052|Adventure Time Ma...|            6|     1|\n",
      "|      00032|Big Trouble In Li...|           11|     1|\n",
      "|      01149| Broken World (Boom)|            2|     1|\n",
      "|      01489|Jim Henson Labyri...|            1|     1|\n",
      "+-----------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_comics_sold.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_comics_sold = total_comics_sold[['account_num', 'comic_title', 'bought']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61871 3\n"
     ]
    }
   ],
   "source": [
    "print(total_comics_sold.count(), len(total_comics_sold.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting\n",
    "\n",
    "Sooooooo, I forgot that the values need to be numeric. So need to fix that.\n",
    "\n",
    "#### Convert `account_id` to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_int_udf = F.udf(dfc.make_int, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_num_col = total_comics_sold['account_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_num: string, comic_title: string, bought: int, account_id: int]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_comics_sold = total_comics_sold.withColumn('account_id'\n",
    "                                        ,to_int_udf(account_num_col))\n",
    "total_comics_sold.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------+----------+\n",
      "|account_num|         comic_title|bought|account_id|\n",
      "+-----------+--------------------+------+----------+\n",
      "|      02247|Bubblegun VOL 2 (...|     1|      2247|\n",
      "|      00487|Captain Swing (Av...|     1|       487|\n",
      "|      00029|God Is Dead (Avatar)|     1|        29|\n",
      "|      01260| Providence (Avatar)|     1|      1260|\n",
      "|      00172|   Supergod (Avatar)|     1|       172|\n",
      "|      02493|       Abbott (Boom)|     1|      2493|\n",
      "|      00052|Adventure Time Ma...|     1|        52|\n",
      "|      00032|Big Trouble In Li...|     1|        32|\n",
      "|      01149| Broken World (Boom)|     1|      1149|\n",
      "|      01489|Jim Henson Labyri...|     1|      1489|\n",
      "+-----------+--------------------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_comics_sold.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61871 4\n"
     ]
    }
   ],
   "source": [
    "print(total_comics_sold.count(), len(total_comics_sold.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to find a way to give ids to the `comic_title`. Kind of clunky, but I do have the version in PostgreSQL of the big table. I can just build an ID table up there as source of truth. I could do something on PySpark side, but then think would want to save it somewhere (e.g. the DB) anyway. So might as well do it from the top.\n",
    "\n",
    "#### Get `comic_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[comic_id: bigint, comic_title: string]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comics = spark.read.json('raw_data/comics.json')\n",
    "comics.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7202"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comics.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|comic_id|         comic_title|\n",
      "+--------+--------------------+\n",
      "|       1|0Secret Wars (Mar...|\n",
      "|       2|100 Bullets Broth...|\n",
      "|       3|100 Penny Press L...|\n",
      "|       4|100 Penny Press S...|\n",
      "|       5|100 Penny Press T...|\n",
      "|       6|100 Penny Press T...|\n",
      "|       7|100th Anniversary...|\n",
      "|       8|12 Reasons To Die...|\n",
      "|       9|    13 Coins (Other)|\n",
      "|      10|13th Artifact One...|\n",
      "+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comics.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7202 2\n"
     ]
    }
   ],
   "source": [
    "print(comics.count(), len(comics.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to join this back into `total_comics_sold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set aliases\n",
    "tot = total_comics_sold.alias('tot')\n",
    "com = comics.alias('com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+\n",
      "|account_id|comic_id|bought|\n",
      "+----------+--------+------+\n",
      "|      2247|     995|     1|\n",
      "|       487|    1102|     1|\n",
      "|        29|    2680|     1|\n",
      "|      1260|    4870|     1|\n",
      "|       172|    6023|     1|\n",
      "|      2493|      66|     1|\n",
      "|        52|     116|     1|\n",
      "|        32|     755|     1|\n",
      "|      1149|     971|     1|\n",
      "|      1489|    3503|     1|\n",
      "+----------+--------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tot_sold_ids_only = tot.join(com.select('comic_id','comic_title')\n",
    "                      ,tot.comic_title==com.comic_title).select('account_id'\n",
    "                                                                , 'comic_id'\n",
    "                                                                , 'bought')\n",
    "tot_sold_ids_only.persist()\n",
    "tot_sold_ids_only.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account_id: integer (nullable = true)\n",
      " |-- comic_id: long (nullable = true)\n",
      " |-- bought: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tot_sold_ids_only.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61871 3\n"
     ]
    }
   ],
   "source": [
    "print(tot_sold_ids_only.count(), len(tot_sold_ids_only.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we save this 'clean' df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_input_df = tot_sold_ids_only.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61871, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_input_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_input_df.to_json('raw_data/als_input_filtered.json', orient='records'\n",
    "                     ,lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"account_id\":2247,\"comic_id\":995,\"bought\":1}\r\n",
      "{\"account_id\":487,\"comic_id\":1102,\"bought\":1}\r\n",
      "{\"account_id\":29,\"comic_id\":2680,\"bought\":1}\r\n",
      "{\"account_id\":1260,\"comic_id\":4870,\"bought\":1}\r\n",
      "{\"account_id\":172,\"comic_id\":6023,\"bought\":1}\r\n",
      "{\"account_id\":2493,\"comic_id\":66,\"bought\":1}\r\n",
      "{\"account_id\":52,\"comic_id\":116,\"bought\":1}\r\n",
      "{\"account_id\":32,\"comic_id\":755,\"bought\":1}\r\n",
      "{\"account_id\":1149,\"comic_id\":971,\"bought\":1}\r\n",
      "{\"account_id\":1489,\"comic_id\":3503,\"bought\":1}\r\n"
     ]
    }
   ],
   "source": [
    "!head raw_data/als_input_filtered.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS Model\n",
    "\n",
    "Let's start with  train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test set\n",
    "(train, test) = tot_sold_ids_only.randomSplit([.8, .2], seed=41916)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure shapes make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49536 3\n"
     ]
    }
   ],
   "source": [
    "print(train.count(), len(train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12335 3\n"
     ]
    }
   ],
   "source": [
    "print(test.count(), len(test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd Run @ ALS with filtered dataset\n",
    "\n",
    "- Minimum number of titles bought by account = 5\n",
    "- Maximum number of titles bought by account = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started on Thu Jun 27 21:05:30 2019.\n"
     ]
    }
   ],
   "source": [
    "now = time.ctime(int(time.time()))\n",
    "print(\"Started on {}.\".format(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ALS instance and fit model\n",
    "als = ALS(maxIter=20,\n",
    "          rank=10,\n",
    "          userCol='account_id',\n",
    "          itemCol='comic_id',\n",
    "          ratingCol='bought',\n",
    "          alpha=1.0,\n",
    "          implicitPrefs=True,\n",
    "          seed=41916)\n",
    "model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed on Thu Jun 27 21:12:52 2019.\n"
     ]
    }
   ],
   "source": [
    "now = time.ctime(int(time.time()))\n",
    "print(\"Completed on {}.\".format(now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_id: int, comic_id: bigint, bought: int, prediction: float]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions on TEST\n",
    "predictions = model.transform(test)\n",
    "predictions.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+------------+\n",
      "|account_id|comic_id|bought|  prediction|\n",
      "+----------+--------+------+------------+\n",
      "|       133|     471|     1|  0.12044321|\n",
      "|      1489|     496|     1|0.0011770985|\n",
      "|       579|     496|     1| 0.006886015|\n",
      "|      2770|     833|     1|0.0036284635|\n",
      "|      2573|     833|     1|   0.0761981|\n",
      "|      1621|    1959|     1|  0.09269879|\n",
      "|      1748|    1959|     1| 0.015198524|\n",
      "|      1632|    1959|     1|  0.15759571|\n",
      "|       986|    1959|     1|  0.10084282|\n",
      "|        49|    1959|     1| 0.008000695|\n",
      "+----------+--------+------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BinaryClassificationEvaluator` only likes doubles for `rawPredictionCol`, so cast it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.withColumn(\"prediction\", predictions[\"prediction\"].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+--------------------+\n",
      "|account_id|comic_id|bought|          prediction|\n",
      "+----------+--------+------+--------------------+\n",
      "|       133|     471|     1| 0.12044321000576019|\n",
      "|      1489|     496|     1|0.001177098485641...|\n",
      "|       579|     496|     1|0.006886015180498362|\n",
      "|      2770|     833|     1|0.003628463484346...|\n",
      "|      2573|     833|     1| 0.07619810104370117|\n",
      "|      1621|    1959|     1| 0.09269879013299942|\n",
      "|      1748|    1959|     1|0.015198524110019207|\n",
      "|      1632|    1959|     1|  0.1575957089662552|\n",
      "|       986|    1959|     1| 0.10084281861782074|\n",
      "|        49|    1959|     1|0.008000695146620274|\n",
      "+----------+--------+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Evaluation\n",
    "\n",
    "Based on our first swing of the bat:\n",
    "- `maxIter` = 20\n",
    "- `rank` = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(metricName='areaUnderROC'\n",
    "                                          ,labelCol='bought'\n",
    "                                          ,rawPredictionCol='prediction'\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under the Curve = 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Area Under the Curve = \" + str(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **REALLY?** \n",
    "Smells weird. Especially when we look at the actual `prediction` values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas dataframe\n",
    "pred_df = predictions.select('*').toPandas()\n",
    "\n",
    "# Check nulls\n",
    "pred_num_nulls = pred_df['prediction'].isna().sum()\n",
    "\n",
    "# Num rows\n",
    "preds_attempted = pred_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 360 nulls out of 12335.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} nulls out of {}.\".format(pred_num_nulls, preds_attempted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So 0.03% are nulls.\n"
     ]
    }
   ],
   "source": [
    "print(\"So {:.2f}% are nulls.\".format(pred_num_nulls/preds_attempted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, they're such a tiny portion of the test set, for now let's remove the nulls for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12335"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to spark dataframe\n",
    "predictions = spark.createDataFrame(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+----------+\n",
      "|account_id|comic_id|bought|prediction|\n",
      "+----------+--------+------+----------+\n",
      "|         0|       0|     0|       360|\n",
      "+----------+--------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select([count(when(isnan(c), c)).alias(c) for c in predictions.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_no_na = predictions.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[account_id: bigint, comic_id: bigint, bought: bigint, prediction: double]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_no_na.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11975"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_no_na.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model by computing the AUC on the test data\n",
    "auc2 = evaluator.evaluate(pred_no_na)\n",
    "\n",
    "print(\"AUC = \" + str(auc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so that gives us a baseline. Let's see if we can do a little grid search action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do that, some testing shows that I can't get the BinaryEvaluator to work because I need to manually cast the `predictionCol` to double, but can't do that while encapsulated inside of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model by computing the RMSE on the test data\n",
    "eval_reg = RegressionEvaluator(metricName=\"rmse\", labelCol=\"bought\",\n",
    "                                predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parameter grid\n",
    "params = (ParamGridBuilder()\n",
    "          .addGrid(als.regParam, [1, 0.01, 0.001, 0.1])\n",
    "          .addGrid(als.maxIter, [5, 10, 20])\n",
    "          .addGrid(als.rank, [4, 10, 50])\n",
    "          .addGrid(als.alpha, [.01, 0.1, 1, 10, 40])).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = TrainValidationSplit(estimator=als\n",
    "                          , evaluator=evaluator\n",
    "                          , estimatorParamMaps=params\n",
    "                          , trainRatio=0.8)\n",
    "#cv = CrossValidator(estimator=als_implicit, estimatorParamMaps=paramGrid, evaluator=RegressionEvaluator())\n",
    "model_implicit = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cross validate for best hyperparameters\n",
    "cv = CrossValidator(estimator=als\n",
    "                    ,estimatorParamMaps=params\n",
    "                    ,evaluator=evaluator\n",
    "                    ,parallelism=4\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.ctime(int(time.time()))\n",
    "print(\"Completed on {}.\".format(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and store model\n",
    "best_model = cv.fit(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_model = best_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.ctime(int(time.time()))\n",
    "print(\"Completed on {}.\".format(now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Top N recommendations for Single User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a reference list of `account_id`'s, for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|account_id|\n",
      "+----------+\n",
      "|      2185|\n",
      "|      1663|\n",
      "|         5|\n",
      "|       775|\n",
      "|       604|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_to_test = 5\n",
    "\n",
    "users = (tot_sold_ids_only.select(als.getUserCol())\n",
    "                          .sample(False\n",
    "                                  ,n_to_test/tot_sold_ids_only.count()\n",
    "                                  ,41916)\n",
    "        )\n",
    "users.persist()\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We developed and wrote the functionality out to a function in `comic_recs.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Testing function!\n",
    "\n",
    "- Pass the function to a pandas dataframe. \n",
    "- Function will ask for an account_id.\n",
    "- Will return top n, n defined in parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2185\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comic_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gideon Falls (Image)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ad After Death Book 01 (of 3 (Image)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ad After Death Book 02 (of 3 (Image)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Royal City (Image)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ad After Death Book 03 (of 3 (Image)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            comic_title\n",
       "1                  Gideon Falls (Image)\n",
       "2  Ad After Death Book 01 (of 3 (Image)\n",
       "3  Ad After Death Book 02 (of 3 (Image)\n",
       "4                    Royal City (Image)\n",
       "5  Ad After Death Book 03 (of 3 (Image)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_df = cr.get_top_n_recs_for_user(spark=spark, model=model, topn=5)\n",
    "top_n_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1663\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comic_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Darth Vader (Marvel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Star Wars Vader Down (Marvel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Star Wars Annual (Marvel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Star Wars (Marvel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Journey Star Wars Fase (Marvel)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       comic_title\n",
       "1             Darth Vader (Marvel)\n",
       "2    Star Wars Vader Down (Marvel)\n",
       "3        Star Wars Annual (Marvel)\n",
       "4               Star Wars (Marvel)\n",
       "5  Journey Star Wars Fase (Marvel)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_df = cr.get_top_n_recs_for_user(spark=spark, model=model, topn=5)\n",
    "top_n_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comic_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Star Wars (Marvel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Star Wars Vader Down (Marvel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Darth Vader (Marvel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Star Wars Annual (Marvel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>East of West (Image)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     comic_title\n",
       "1             Star Wars (Marvel)\n",
       "2  Star Wars Vader Down (Marvel)\n",
       "3           Darth Vader (Marvel)\n",
       "4      Star Wars Annual (Marvel)\n",
       "5           East of West (Image)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_df = cr.get_top_n_recs_for_user(spark=spark, model=model, topn=5)\n",
    "top_n_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "- OK this seems more realistic(?) Only three tests, but it seems more realistic that two users would completely different recommendations, than other results I've seen to date, where there would be overlap of 2 or 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
